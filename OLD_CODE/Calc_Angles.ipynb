{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed3e03a7-c58c-49b0-9042-4cee5342a18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "875ffcb0-d85f-43a4-a5ff-9567c3200e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_topology_data(filepath):\n",
    "    \n",
    "    \"\"\"Reads topology data from a .top file.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): Path to the .top file containing trajectory data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame of the topology file\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load your dataset\n",
    "    df = pd.read_csv(filepath, header = None)\n",
    "    \n",
    "    # Remove the first row\n",
    "    df = df.iloc[1:].reset_index(drop=True)    \n",
    "    df = df.iloc[:, 0]\n",
    "\n",
    "\n",
    "    #returns the formatted topology file\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0957d087-ef27-4625-921b-dca7ff39b701",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '4m1_6NT_1.top'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m top \u001b[38;5;241m=\u001b[39m read_topology_data(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4m1_6NT_1.top\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 13\u001b[0m, in \u001b[0;36mread_topology_data\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Reads topology data from a .top file.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m    pd.DataFrame of the topology file\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Load your dataset\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(filepath, header \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Remove the first row\u001b[39;00m\n\u001b[1;32m     16\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)    \n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '4m1_6NT_1.top'"
     ]
    }
   ],
   "source": [
    "top = read_topology_data('4m1_6NT_1.top')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc24162c-2722-48d8-883a-70c2e9d8df1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_arm_indecies(filepath, SE, armNum, SEspacer, coreSpacer):\n",
    "\n",
    "    \"\"\"\n",
    "    Finds the index numbers that correspond to a single arm. Will append these indecies to core and end lists\n",
    "\n",
    "    Args:\n",
    "        filepath (str): Path to the .top file containing trajectory data.\n",
    "        SE (int): The number of sticky ends on a strand\n",
    "        armNum (int): The number of arms the nanostar has\n",
    "        SEspacer (int): The number of nucleotides that make up the spacer before the SE\n",
    "        starting_indecies (list)\n",
    "        ending_indecies (list)\n",
    "\n",
    "    Returns:\n",
    "        core and end indeciex list\n",
    "    \"\"\"\n",
    "    #reads in the topology data\n",
    "    topology = read_topology_data(filepath)\n",
    "\n",
    "    # print(topology)\n",
    "\n",
    "    strandCount = 0\n",
    "    index_count = 0\n",
    "\n",
    "    #Calculate the length of the strand\n",
    "    strandLength = (topology.size)/armNum\n",
    "    # print(strandLength)\n",
    "    seq_length = int(strandLength-SE-SEspacer-coreSpacer)/2\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    #defines a single strand that makes up the double stranded arm\n",
    "    s = 0\n",
    "\n",
    "    #defines whether the end of the double stranded arm has been reached\n",
    "    end = False\n",
    "\n",
    "\n",
    "    #list holds all the indecies for the core and ends\n",
    "    indecies = []\n",
    "\n",
    "    #continues to loop\n",
    "    while True:\n",
    "\n",
    "        #appends each index, will start by appending an index of 0\n",
    "        # print(topology.iloc[i])\n",
    "        indecies.append(i)\n",
    "\n",
    "        #if the stand number is even\n",
    "        #checks for the start of a single strand\n",
    "        if s%2 == 0:\n",
    "\n",
    "            #single strands have a length of 15 nucleotides\n",
    "            #this will find the ending of the single strand\n",
    "            #seqlengh -1\n",
    "            i+= 14\n",
    "\n",
    "        #if instead at the end of the single strand\n",
    "        elif end == False:\n",
    "\n",
    "            #add 3 to account for the core spacers and to move to the start of the next single strand\n",
    "            #that makes up the double stranded arm\n",
    "            #coreSpacer + 1\n",
    "            i+= 3\n",
    "            \n",
    "\n",
    "            #also sents end to TRUE since the end of the double strand is approaching\n",
    "            end = True\n",
    "\n",
    "        #when the end of the double stranded arm is reached (end = TRUE)\n",
    "        else:\n",
    "\n",
    "            #accounts for the spacer and the SE to go to the next strand\n",
    "            #SE + SEspacer + 1\n",
    "            i+= 8\n",
    "\n",
    "            #sets end to FALSE again since a new strand has started\n",
    "            end = False\n",
    "\n",
    "        #exit condition\n",
    "        if i >= topology.size:\n",
    "            break\n",
    "\n",
    "        #incremented each time an index is added\n",
    "        s+= 1\n",
    "\n",
    "    #creating core and end indecies list\n",
    "    core_indecies = []\n",
    "    end_indecies = []\n",
    "\n",
    "    #appends the first element to the end_indecies list   \n",
    "    end_indecies.append(indecies[0])\n",
    "\n",
    "    #used to append every 2 elements from indecies into respective list\n",
    "    loop = 1\n",
    "\n",
    "    #round - used to alternate appending to the end or core indecies lists\n",
    "    rnd = 0\n",
    "\n",
    "    #continues to run\n",
    "    while True:\n",
    "\n",
    "        #if the loop index exceeds the bound for the index\n",
    "        if (loop + 2) >= len(indecies):\n",
    "            #break the while loop\n",
    "            break\n",
    "\n",
    "        #if the round is even\n",
    "        if rnd % 2 == 0:\n",
    "            #append the indecies to core_indecies list\n",
    "            core_indecies.append((indecies[loop], indecies[loop+1]))\n",
    "\n",
    "        #if the round is odd\n",
    "        else:\n",
    "            #append the idencies to end_indecies list\n",
    "            end_indecies.append(indecies[loop+1])\n",
    "\n",
    "        #increment the loop by 2 to account for appending every 2 elements to a different list\n",
    "        loop += 2\n",
    "        #increment the loop by 1 to do binary list selection\n",
    "        rnd +=1\n",
    "\n",
    "    \n",
    "\n",
    "    avg_core = []\n",
    "\n",
    "    #Take averages of the core index pairs\n",
    "    for pair in core_indecies:\n",
    "        avg_core.append(int(statistics.mean(pair)))\n",
    "\n",
    "    #\n",
    "\n",
    "    return avg_core, end_indecies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b55b637-abe4-489b-a325-cf7f2dfc5e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([15, 54, 93, 132, 171], [0, 39, 78, 117, 156])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_arm_indecies('/Users/pradnyakadam/Downloads/ACS_Manuscript/5_arm_INPUT_FILES/5m_6NT_2bp.top', 6, 5, 1, 2)\n",
    "\n",
    "#1, 15, 18, 32, 40, 54, 57, 71, 79, 93, 96, 110, 118, 132, 135,149\n",
    "#0 - end, 14 - core, 17 - core, 31 - end, 39 - end, 53 - core, 56 - core, 70 - end, 78 - end, 92 -core, 95 -core, 109 -end, \n",
    "#117 - end, 131 - core, 134 - core, 148 - end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f6125bc-0c76-4e09-9013-9e16186be0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_center_of_mass(dataframes, core_indecies):\n",
    "    \"\"\"Calculates the average center of mass for core nucleotides at each timestamp.\n",
    "\n",
    "    Args:\n",
    "        dataframes (list[pd.DataFrame]): List of DataFrames containing particle positions.\n",
    "        core_nucleotides (int): Number of core nucleotides in the nanostar.\n",
    "        arms (int): Number of arms in the nanostar.\n",
    "        sequence_length (int): Total sequence length of the nanostar.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe containing average center of mass (COM) for each timestamp.\n",
    "        Each row of the Dataframe corresponds to a new timestamp.\n",
    "    \"\"\"\n",
    "\n",
    "    #creates a list to store average X, Y, and Z center of mass coordinates\n",
    "    x_avg, y_avg, z_avg = [], [], []\n",
    "    \n",
    "    # arm_length = int((sequence_length - core_nucleotides) / (2 * armNum))\n",
    "\n",
    "    #iterates through each time point's dataframe\n",
    "    for df in dataframes:\n",
    "\n",
    "        #creates lists to store the coordinates corresponding to each index in core_indecies list\n",
    "        #stores the x, y, and z coordinates separately\n",
    "        x_centers, y_centers, z_centers = [], [], []\n",
    "\n",
    "        #iterates through the indecies in the core_indecies list\n",
    "        for index in core_indecies:\n",
    "\n",
    "            #adds the corresponding positional coordinate to its respective list\n",
    "            x_centers.append(float(df.iloc[index, 0]))\n",
    "            y_centers.append(float(df.iloc[index, 1]))\n",
    "            z_centers.append(float(df.iloc[index, 2]))\n",
    "                \n",
    "\n",
    "        #averages the positional coordinates stored in the x, y, and z centers lists\n",
    "        #this will provide the average center of mass at a single time point\n",
    "        x_avg.append(statistics.mean(x_centers))\n",
    "        y_avg.append(statistics.mean(y_centers))\n",
    "        z_avg.append(statistics.mean(z_centers))\n",
    "\n",
    "    return pd.DataFrame({\"COM_X\": x_avg, \"COM_Y\": y_avg, \"COM_Z\": z_avg})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "110fb670-f71d-4ad2-b7c4-0e08b8fa1fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle_between_arms(dataframes, com_dataframe, arm1_index, arm2_index):\n",
    "    \"\"\"Calculates the angle between two specified arms at each timestamp.\n",
    "\n",
    "    Args:\n",
    "        dataframes (list[pd.DataFrame]): List of DataFrames containing particle positions.\n",
    "        com_dataframe (pd.DataFrame): Dataframe containing center of mass (COM) positions.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        list of angles formed by the selected arms over all the time points\n",
    "    \"\"\"\n",
    "\n",
    "    #variable to iterate through each line of the center of mass df\n",
    "    #as mentioned above each line of the com_dataframe represents a single timestamp of the simulation\n",
    "    #this will ensure that each starting point is at the center of mass for the specific timestamp\n",
    "    com_df = 0\n",
    "\n",
    "    #list to hold all the angles created between two arms\n",
    "    angles_list = []\n",
    "\n",
    "    #iterates through each time point's dataframe\n",
    "    for df in dataframes:\n",
    "\n",
    "        #defines the starting point as the coordinates position associated with the particular timestamp\n",
    "        #refernce comment above for more info.\n",
    "        start_pt = np.array([com_dataframe.iloc[com_df, 0], com_dataframe.iloc[com_df, 1], com_dataframe.iloc[com_df, 2]])\n",
    "#         print(\"start: \", start_pt)\n",
    "\n",
    "        #defining vector 1 end point based on the provided index\n",
    "        end_pt_1 = np.array([float(df.iloc[arm1_index, 0]), float(df.iloc[arm1_index, 1]), float(df.iloc[arm1_index, 2])])\n",
    "#         print(\"ep1: \", end_pt_1)\n",
    "\n",
    "        #defining vector 2 end point based on the other provided index\n",
    "        end_pt_2 = np.array([float(df.iloc[arm2_index, 0]), float(df.iloc[arm2_index, 1]), float(df.iloc[arm2_index, 2])])\n",
    "#         print(\"ep2: \", end_pt_2)\n",
    "\n",
    "        #increment the com_df variable to go to the next timestamp's ceneter of mass\n",
    "        com_df += 1\n",
    "\n",
    "        #defining vectors 1 & 2 based on their corresponding end points\n",
    "        v1 = end_pt_1 - start_pt\n",
    "        v2 = end_pt_2 - start_pt\n",
    "\n",
    "        #using the equation mathematical equation: \n",
    "        \n",
    "        #calculating the dot product of the two vectors\n",
    "        dot_product = np.dot(v1, v2)\n",
    "\n",
    "        #calculating both vectors' magnitudes\n",
    "        magnitude1 = np.linalg.norm(v1)\n",
    "        magnitude2 = np.linalg.norm(v2)\n",
    "\n",
    "        calc = dot_product / (magnitude1 * magnitude2)\n",
    "\n",
    "        if calc > 1 or calc < -1:\n",
    "            calc = 0\n",
    "\n",
    "        #calculating the angle created between the two vectors (in radians)\n",
    "        angle_radians = np.arccos(calc)\n",
    "\n",
    "        #converting that value to degrees\n",
    "        angle_degrees = np.degrees(angle_radians)\n",
    "        \n",
    "#         print(\"angle degrees: \", angle_degrees)\n",
    "\n",
    "        #appending the calculated angle (based on the timestamp) to the list creeated above\n",
    "        angles_list.append(angle_degrees)\n",
    "        \n",
    "#         print(\"done\")\n",
    "    \n",
    "    return angles_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538e6638-ee8a-43aa-9b18-73a019ccc208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fb028a2-ba05-40a0-9fe9-58e62a7fc2df",
   "metadata": {},
   "source": [
    "### Public Function\n",
    "\n",
    "Calculates the angles for each strand\n",
    "\n",
    "0, 39, 78, 117\n",
    "\n",
    "indecies: \n",
    "- (C --> 0) => arm 1 (strands 1 & 2)\n",
    "- (C --> 78) => arm 2 (strands 2 & 3)\n",
    "- (C --> 117) => arm 3 (strands 3 & 4)\n",
    "- (C --> 39) => arm 4 (strands 1 & 4)\n",
    "\n",
    "Will be finding the angle between:\n",
    "- arms 1 & 2 --> vector: (C --> 0) & (C --> 78)\n",
    "- arms 2 & 3 --> vector: (C --> 78) & (C --> 117)\n",
    "- arms 3 & 4 --> vector: (C --> 117) & (C --> 39)\n",
    "- arms 1 & 4 --> vector: (C --> 39) & (C --> 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5eb41051-858c-4bc7-82c7-40ab67e38abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_angles(dataframes, topFile, SE, armNums, SEspacer, coreSpacer):\n",
    "\n",
    "    \"\"\"\n",
    "    Returns the angles for each theta at all the different time points.\n",
    "\n",
    "    Args:\n",
    "        dataframes (list[pd.DataFrames]): List of DataFrames containing particle positions.\n",
    "\n",
    "    Returns:\n",
    "        list of angles for each theta value at each time point\n",
    "    \"\"\"\n",
    "\n",
    "    avg_core_indecies, end_indecies = find_arm_indecies(topFile, SE, armNums, SEspacer, coreSpacer)\n",
    "    com_dfs = find_center_of_mass(dataframes, avg_core_indecies)\n",
    "\n",
    "    #theta1: angle btw arms 1 & 2\n",
    "    #theta2: angle btw arms 2 & 3\n",
    "    #theta3: angle btw arms 3 & 4\n",
    "    #theta4: angle btw arms 1 & 4\n",
    "\n",
    "    #NOTE THE INDECIES WILL CHANGE FOR DIFFERENT ARMED NANOSTAR\n",
    "\n",
    "    #calculate_angle_between_arms(dataframes, com_dataframe, arm1_index, arm2_index)\n",
    "    \n",
    "    theta1 = calculate_angle_between_arms(dataframes, com_dfs, 0, 78)\n",
    "    theta2 = calculate_angle_between_arms(dataframes, com_dfs, 78, 117)\n",
    "    theta3 = calculate_angle_between_arms(dataframes, com_dfs, 39, 117)\n",
    "    theta4 = calculate_angle_between_arms(dataframes, com_dfs, 39, 0)\n",
    "\n",
    "    return pd.DataFrame({'θ1' : theta1,\n",
    "                         'θ2' : theta2,\n",
    "                         'θ3' : theta3,\n",
    "                         'θ4' : theta4})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
